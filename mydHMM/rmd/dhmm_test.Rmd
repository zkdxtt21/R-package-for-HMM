---
title: "Discrete Hidden Markov Chain Inference Test"
author: "Group Four"
date: "April / 27 / 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## I. Package Introduction

This is a R markdown document for our package mydHMM. We will give a quick intro to our major functions 
and give a example in the later part II, and the result are showing in the part III.

*dhmm.model*: initialize a random hidden markov model     
*dhmm.sim*: simulate states and observations from a given Hidden Markov Model    
*dhmm.estimate*: estimate all parameters of hmm given observations  
*dhmm.viterbi*: find the max possible hidden state sequence given a HMM 
*dhmm.decoding*: return estimate model and max possible hidden state sequence given observations

The following code automatically generated samples from a given hidden markov model
```{r definition, echo=FALSE}
### Generate a DHMM Model
dhmm.model <- function(lambda, mc_type = 'eq_full') {
  states <- seq(1, lambda,  length.out = lambda)
  if (mc_type == 'eq_full') { transp <- matrix(rep(1 / lambda, lambda^2), nrow = lambda) }
  else if (mc_type == 'rd_full') { transp <- matrix(rep(1 / lambda, lambda^2), nrow = lambda) }
  else if (mc_type == 'count') {
    transp <- matrix(rep(1 / lambda, lambda^2), nrow = lambda) 
  }
  else {
    transp <- matrix(rep(1 / lambda, lambda^2), nrow = lambda) 
  }
  set.seed(123)
  mu <- round((lambda * runif(lambda) / 2), 2)
  set.seed(234)
  sd <- round(runif(lambda), 2)
  res <- list(states, transp, mu, sd)
  return (res)
}
### samples DHMM
dhmm.sim <- function(model, sample_size = 1) {
  dhmm <- model
  # get states, transp, mu, var
  states <- dhmm[[1]]
  transp <- dhmm[[2]]
  mu <- dhmm[[3]]
  sd <- dhmm[[4]]
  # return var augment
  samples <- rep(NA, sample_size)
  obser <- rep(NA, sample_size)
  # initialize uniformly
  samples[1] <- sample(states, 1, replace = TRUE)
  obser[1] <- rnorm(1, mu[samples[1]], sd[samples[1]])
  for (i in 2:sample_size) {
    samples[i] <- sample(states, 1, prob = transp[samples[i-1], ], replace = TRUE)
    obser[i] <- rnorm(1, mu[samples[i]], sd[samples[i]])
  }  
  res <- list(samples, obser)
  return (res)
}
dhmm.forward <- function(model, obser) {
  # get states, transp, mu, sd
  states <- model[[1]]
  transp <- model[[2]]
  mu <- model[[3]]
  sd <- model[[4]]
  time_stp <- length(obser)
  state_num <- length(states)
  # create a forward table
  forward <- matrix(rep(NA, time_stp * state_num), nrow = state_num)
  # create a scaling vector
  scaling <- rep(NA, time_stp)
  # initialize 
  forward[,1] <- rep(1/state_num, state_num) * dnorm(rep(obser[1], state_num), mean=mu, sd=sd)
  scaling[1] <- 1 / sum(forward[,1])
  forward[,1] <- forward[,1] * scaling[1]
  for (i in 2:time_stp) {
    forward[,i] <- forward[,i-1] %*% 
                   transp * dnorm(rep(obser[i], state_num), mean=mu, sd=sd)
    scaling[i] <- 1 / sum(forward[,i])
    forward[,i] <- forward[,i] * scaling[i]
  }
  return ( list(forward, scaling) )
}
# compute backward procedure given model
dhmm.backward <- function(model, obser, scaling) {
  # get states, transp, mu, sd
  states <- model[[1]]
  transp <- model[[2]]
  mu <- model[[3]]
  sd <- model[[4]]
  time_stp <- length(obser)
  state_num <- length(states)
  # create a backward table
  backward <- matrix(rep(NA, time_stp * state_num), nrow = state_num)
  # initialize 
  backward[, time_stp] <- rep(1, state_num) * scaling[time_stp]
  for (i in time_stp:2) {
    
    tmp <- backward[, i] * dnorm(rep(obser[i], state_num), mean=mu, sd=sd)
    backward[, i-1] <- transp %*% tmp * scaling[i-1]
  }
  return (backward)
}
# estimate the DHMM model given the obser & a initial model
dhmm.estimate <- function(ini_dhmm, obser, epsilon = 0.0001, max_iter = 1000) {
  # using Baum-Welch algorithm

  time_stp <- length(obser)
  state_num <- length(ini_dhmm[[1]])
  # save log-likehihood seqence
  log_likeli <- c(0, 1)
  iter <- 2

  while (abs(log_likeli[iter]-log_likeli[iter-1]) > epsilon & iter <= max_iter) {

    # print(ini_dhmm)
    forward_res <- dhmm.forward(ini_dhmm, obser)
    forward <- forward_res[[1]]
    scaling <- forward_res[[2]]
    backward <- dhmm.backward(ini_dhmm, obser, scaling)

    transp <- ini_dhmm[[2]]
    mu <- ini_dhmm[[3]]
    sd <- ini_dhmm[[4]]

    ## -------------  E-steps ------------------
    gamma_mtx <- matrix(rep(NA, state_num * time_stp), nrow = state_num)
    xi <- list()
    for (i in 1:(time_stp-1)) {

      tmp <- backward[,i+1] * dnorm(rep(obser[i+1], state_num), mean=mu, sd=sd)
      xi_i <- diag(forward[,i]) %*% transp %*% diag(tmp)
      xi[[i]] <- xi_i
      gamma_mtx[ ,i] = rowSums(xi_i)
    }
    gamma_mtx[,time_stp] = forward[,time_stp]

    log_likeli <- c(log_likeli, -round(sum(log(scaling)), 2))

    ## ------------- M-steps -------------------

    # estimate transit matrix
    xi_sum <- matrix(rep(0, state_num ^ 2), nrow = state_num)
    for (i in 1:(time_stp-1)) {

      xi_sum <- xi_sum + xi[[i]]
    }
    ini_dhmm[[2]] <- xi_sum / rowSums(gamma_mtx)

    # estimate mu, sd
    ini_dhmm[[3]] <- gamma_mtx %*% obser / rowSums(gamma_mtx)
    ini_dhmm[[3]] = c(ini_dhmm[[3]])
    mu_mtx <-  matrix(rep(mu, time_stp), nrow = state_num)
    obser_mtx <- matrix(rep(obser, state_num), nrow = state_num, byrow = TRUE)
    var_mtx <- (obser_mtx - mu_mtx) ^ 2
    ini_dhmm[[4]] <- sqrt(rowSums(gamma_mtx * var_mtx) / rowSums(gamma_mtx))

    iter <- iter + 1
  }

  log_likeli <- log_likeli[3:length(log_likeli)]
  # print(log_likeli)
  return (list(ini_dhmm, log_likeli))
}
# given X and estimate model, get esitimate of hidden state sample
dhmm.viterbi <- function(model, obser) {
  
  # get states, transp, mu, var
  states <- model[[1]]
  transp <- model[[2]]
  mu <- model[[3]]
  sd <- model[[4]]
  
  time_stp <- length(obser)
  state_num <- length(states)
  
  # create a prob mtx and best_path matrix
  prob_mtx <- matrix(rep(NA, state_num * time_stp), nrow = state_num)
  best_path <- prob_mtx
  scaling <- rep(NA, time_stp)
  
  prob_mtx[, 1] <- colSums(transp)/sum(colSums(transp)) * 
                   dnorm(rep(obser[1], state_num), mean=mu, sd=sd)
  scaling[1] = sum(prob_mtx[, 1])
  prob_mtx[, 1] = prob_mtx[, 1]/scaling[1]
  best_path[, 1] <- 0
  
  for (i in 2:time_stp) {
    for (j in 1:state_num) {
      
      tmp <- prob_mtx[, i-1] * transp[, j] * 
             dnorm(obser[i], mean=mu[j], sd=sd[j])
      
      prob_mtx[j, i] <- max(tmp)
      best_path[j, i] <- which.max(tmp)
    }
    scaling[i] = sum(prob_mtx[, i])
    prob_mtx[, i] = prob_mtx[, i]/scaling[i]
  }
  
  best <- rep(NA, time_stp)
  best[time_stp] <- which.max(prob_mtx[, time_stp])
  
  for (i in time_stp:2) {
    best[i-1] <- best_path[best[i], i]
  }
  res <- list(prob_mtx, best)
  return (res)
}
# inference hidden states sequence given a sequence of observations
dhmm.decoding <- function(obser, range = c(2,3,4,5), epsilon = 0.0001, max_iter = 1000) {

  # range is a postive integer vector
  bic <- NULL
  model_list <- NULL
  best_list <- NULL

  time_stp <- length(obser)
  likeli_list <- list()

  for (i in 1:length(range)) {

    lambda <- range[i]

    # using kmeans method to get the initial mu and sd value
    ini_dhmm <- dhmm.model(lambda, 'eq_full')
    kmeans_iter = 100
    mu_ini <- matrix(rep(NA, kmeans_iter * lambda), nrow = kmeans_iter)
    sd_ini <- matrix(rep(NA, kmeans_iter * lambda), nrow = kmeans_iter)
    for(m in 1:kmeans_iter){
      km <- kmeans(obser, lambda, iter.max = 10)
      mu_ini[m,] <- c(sort(km$centers)) # why c() ???
      ord <- order(km$centers)
      sd_ini[m,] <- sqrt(km$withinss[ord] / (km$size[ord]-1))
    }
    ini_dhmm[[3]] <- apply(mu_ini, 2, mean)
    ini_dhmm[[4]] <- apply(sd_ini, 2, mean)

    # EM to estimate model
    res <- dhmm.estimate(ini_dhmm, obser, epsilon, max_iter)
    dhmm_model <- res[[1]]
    # viterbi algorithm to find best path
    best_gauss <- dhmm.viterbi(dhmm_model, obser)

    ## --------------- BIC compute -----------------##
    likeli_list[[i]] <- res[[2]]
    max_iter <- length(likeli_list[[i]])
    para_num <- lambda * (lambda + 1)
    bic[i] <- (-2) * likeli_list[[i]][max_iter] + log(time_stp) * para_num
    # print(bic[i])

    # save data to list
    model_list[[i]] <- dhmm_model
    best_list <- cbind(best_list, best_gauss[[2]])

  }

  best_model <- model_list[[which(bic == min(bic))]]
  names(best_model) <- c("states", "transition matrix", "mean", "sd")
  best_seq <- best_list[, which(bic == min(bic))]
  
  res <- list(best_model, best_seq, likeli_list)
  names(res) <- c("best_model", "best_seq", "likeli_list")
  return (res)
}
```

```{r}
size <- 400
model <- dhmm.model(4, 'count')
model[[3]] = c(0, 3, 5, 7)
model[[2]] <- matrix(c(0.3, 0.2, 0.3, 0.2,
                       0.2, 0.2, 0.5, 0.1,
                       0.3, 0.3, 0.1, 0.3,
                       0.2, 0.2, 0.3, 0.3), 4, 4, byrow = T)

sim_samples <- dhmm.sim(model, size)
obser <- sim_samples[[2]]
show(obser[1:50])
```

## II. Examples

We can use the generated samples in the first part to test our code, the result will return a list contain: 

**best_estimate model**: a parameter set of hmm, include transition matrix and mean and sd vector 
**decoding sequence**: the estimated sequence of hidden state of hmm  
**likelihood list**: each element in the list represent a sequence of log-likihood value in a full iteration

```{r}
epsilon <- 0.00001
max_iter <- 1000
range <- c(4, 5)
result <- dhmm.decoding(obser, range, epsilon, max_iter)
# show estimated hidden markov model
result[[1]]

```


## III. Results

Furthermore, we can visulize our results, 1).contrast of result and true classification and 2).the converge curve of log-likelihood

In the first plot, colors represent the predicted groups, while symbols represent the true groups

```{r}
plot(obser, pch=sim_samples[[1]], col=result[[2]])
title("Comparison of result and true group")

```

The converge curve of log-likelihood for different parameters (number of hidden states)
```{r}
# converge curve of log-likelihood
curve <- result[[3]]
par(mfrow=c(1,2), pty="s")
plot(c(curve[[1]]), type="b")
title("Number of Hidden State is 4")
plot(c(curve[[2]]), type="b")
title("Number of Hidden State is 5")

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
